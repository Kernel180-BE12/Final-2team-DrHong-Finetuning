# Hugging Face 사전학습 모델 선택 보고서

**작성자**: Manus AI
**작성일**: 2025년 8월 29일

## 1. 개요

본 보고서는 카카오 알림톡 템플릿 생성 및 승인/반려 분류 모델 개발을 위한 최적의 Hugging Face 사전학습 모델을 선정하는 것을 목표로 합니다. 사용자의 요구사항과 제공된 가이드라인에 따라, 각 모델의 크기, 학습 데이터, 벤치마크 점수, 라이선스를 종합적으로 분석하여 총 10개의 후보 모델(생성 모델 5개, 분류 모델 5개)을 선정하고 각 모델의 장단점 및 적합성을 평가합니다.

## 2. 모델 선정 기준

- **모델 크기 (Parameters)**: 모델의 성능과 서빙 비용 간의 트레이드오프를 고려합니다. 일반적으로 파라미터 수가 클수록 성능이 좋지만 비용과 속도 문제가 발생할 수 있습니다.
- **학습 데이터 (Training Data)**: 모델이 학습한 데이터가 목표 작업(알림톡 템플릿 생성/분류)과 얼마나 유사한지 평가합니다. 작업 유사성이 높을수록 파인튜닝 시 더 좋은 성능을 기대할 수 있습니다.
- **벤치마크 점수 (Benchmark Score)**: KLUE, LogicKor 등 공신력 있는 한국어 NLU/NLG 벤치마크 점수를 통해 모델의 객관적인 성능을 평가합니다.
- **라이선스 (License)**: 상업적 이용이 가능한 라이선스(e.g., Apache 2.0, MIT)를 보유한 모델을 우선적으로 고려합니다.




## 3. 생성 모델 후보 (카카오 알림톡 템플릿 생성용)

### 3.1. MLP-KTLim/llama-3-Korean-Bllossom-8B

- **선택 이유**: Llama 3 기반의 최신 모델로, 한국어에 특화된 어휘 확장과 instruction tuning을 통해 한국어 지시 이행 능력이 뛰어납니다. DPO를 적용하여 인간의 선호도를 잘 반영하도록 학습되었습니다.
- **장점**: 
  - Llama 3 라이선스로 상업적 이용이 가능합니다.
  - 한국어 문화와 언어 특성을 고려한 instruction tuning으로 알림톡 템플릿과 같은 특정 형식의 텍스트 생성에 유리합니다.
  - LogicKor 벤치마크에서 우수한 성능을 보여 논리적이고 일관성 있는 문장 생성이 가능합니다.
- **단점**: 
  - 8B 파라미터로 비교적 큰 모델에 속해 서빙 비용이 높을 수 있습니다.
- **적합성 분석**: 상업적 이용이 가능하고 한국어 지시 이행 능력이 뛰어나 알림톡 템플릿 생성 모델의 기반 모델로 매우 적합합니다.

### 3.2. yanolja/EEVE-Korean-Instruct-10.8B-v1.0

- **선택 이유**: SOLAR 모델 기반으로 한국어 어휘를 확장하고 DPO를 적용하여 한국어 생성 능력을 강화했습니다. Apache 2.0 라이선스로 상업적 이용이 자유롭습니다.
- **장점**: 
  - Apache 2.0 라이선스로 상업적 이용에 제약이 없습니다.
  - Open-Orca, Ultrafeedback 등 양질의 데이터를 한국어로 번역하여 학습에 사용해 지시 이행 능력이 뛰어납니다.
  - 명확한 프롬프트 템플릿을 제공하여 사용이 편리합니다.
- **단점**: 
  - 10.8B 파라미터로 후보 모델 중 가장 크기가 커 서빙 비용과 속도 측면에서 불리할 수 있습니다.
- **적합성 분석**: 상업적 이용이 가능하고 한국어 생성 능력이 검증되었지만, 모델 크기가 커서 비용 효율성을 고려해야 합니다. 성능 테스트 후 최종 선택을 결정하는 것이 좋습니다.

### 3.3. NCSOFT/Llama-VARCO-8B-Instruct

- **선택 이유**: Llama 3.1 기반으로 NC Research에서 한국어에 특화하여 추가 학습시킨 모델입니다. LogicKor 벤치마크에서 매우 높은 점수를 기록했습니다.
- **장점**: 
  - Llama 3.1 라이선스로 상업적 이용이 가능합니다.
  - LogicKor 벤치마크에서 Writing, Understanding 등 생성 관련 항목에서 최고 수준의 성능을 보였습니다.
  - SFT와 DPO를 모두 적용하여 지시 이행 능력과 인간 선호도 반영을 모두 고려했습니다.
- **단점**: 
  - 비교적 최신 모델이라 커뮤니티의 사용 후기나 검증 사례가 적을 수 있습니다.
- **적합성 분석**: 벤치마크 성능이 매우 뛰어나고 상업적 이용이 가능하여 알림톡 템플릿 생성에 매우 적합한 후보입니다. Bllossom 모델과 함께 우선적으로 테스트해볼 가치가 있습니다.

### 3.4. LGAI-EXAONE/EXAONE-3.5-7.8B-Instruct

- **선택 이유**: LG AI Research에서 개발한 한국어-영어 이중언어 모델로, 다양한 벤치마크에서 우수한 성능을 보였습니다.
- **장점**: 
  - KoMT-Bench, LogicKor 등 한국어 관련 벤치마크에서 전반적으로 높은 성능을 기록했습니다.
  - 32K의 긴 컨텍스트를 지원하여 복잡하고 긴 요구사항과 정책을 입력으로 처리하는 데 유리합니다.
- **단점**: 
  - **EXAONE AI Model License Agreement 1.1 - NC** 라이선스로 **비상업적 용도로만 사용이 가능**합니다. 상업적 서비스를 고려한다면 사용할 수 없습니다.
- **적합성 분석**: 성능은 매우 뛰어나지만 라이선스 제약으로 인해 상업적 프로젝트에는 부적합합니다. 학술 연구나 내부 테스트 용도로는 고려해볼 수 있습니다.

### 3.5. spow12/Ko-Qwen2-7B-Instruct

- **선택 이유**: Qwen2 모델을 한국어에 맞게 Supervised Fine-tuning한 모델로, 한국어 대화형 AI에 최적화되어 있습니다.
- **장점**: 
  - 한국어 대화 데이터로 학습하여 자연스러운 템플릿 생성에 강점을 보일 수 있습니다.
- **단점**: 
  - **CC-BY-NC-4.0** 라이선스로 **비상업적 용도로만 사용이 가능**합니다.
  - 상대적으로 인기도나 검증된 성능 지표가 부족합니다.
- **적합성 분석**: 라이선스 제약으로 상업적 프로젝트에는 부적합합니다. 개인 프로젝트나 연구 목적으로 활용할 수 있습니다.




## 4. 분류 모델 후보 (알림톡 템플릿 승인/반려 분류용)

### 4.1. Copycats/koelectra-base-v3-generalized-sentiment-analysis

- **선택 이유**: KoELECTRA-base-v3 모델을 기반으로 일반화된 감정 분석(긍정/부정)에 파인튜닝된 모델입니다. Apache 2.0 라이선스로 상업적 이용이 가능합니다.
- **장점**: 
  - Apache 2.0 라이선스로 상업적 이용에 제약이 없습니다.
  - 다양한 도메인의 리뷰 데이터에 대해 일반화된 성능을 보여, 특정 도메인에 치우치지 않은 분류 성능을 기대할 수 있습니다.
  - 긍정/부정 이진 분류 태스크에 특화되어 있어 승인/반려 분류 문제에 직접적으로 적용하기 용이합니다.
- **단점**: 
  - KLUE와 같은 표준 벤치마크 점수가 명시되어 있지 않아 객관적인 성능 비교가 어렵습니다.
- **적합성 분석**: 상업적 이용이 가능하고, 일반적인 긍정/부정 분류에 특화되어 있어 알림톡 템플릿 승인/반려 분류에 매우 적합합니다. 가장 우선적으로 고려할 만한 후보입니다.

### 4.2. daekeun-ml/koelectra-small-v3-nsmc

- **선택 이유**: KoELECTRA-small 모델을 네이버 영화 리뷰 데이터셋(NSMC)으로 파인튜닝한 모델입니다. MIT 라이선스로 상업적 이용이 가능하며 모델 크기가 작아 경제적입니다.
- **장점**: 
  - MIT 라이선스로 상업적 이용이 자유롭습니다.
  - 모델 크기(14.1M)가 매우 작아 서빙 비용이 저렴하고 추론 속도가 빠릅니다.
  - NSMC 데이터셋에서 높은 분류 정확도를 보입니다.
- **단점**: 
  - 네이버 영화 리뷰라는 특정 도메인에 과적합(overfitting)되었을 가능성이 있어, 알림톡 템플릿과 같은 다른 도메인에서는 성능이 저하될 수 있습니다.
- **적합성 분석**: 작고 빠른 모델이 필요할 경우 좋은 선택지입니다. 하지만 도메인 차이로 인한 성능 저하 가능성을 반드시 테스트해야 합니다. 비용 효율성이 가장 중요하다면 고려해볼 만합니다.

### 4.3. klue/bert-base

- **선택 이유**: KLUE 벤치마크의 공식 BERT-base 모델로, 한국어 NLU 태스크의 표준적인 기반 모델입니다.
- **장점**: 
  - 다양한 KLUE 태스크(TC, NLI 포함)에서 검증된 준수한 성능을 보입니다.
  - 특정 도메인에 치우치지 않은 범용적인 언어 이해 능력을 갖추고 있습니다.
- **단점**: 
  - **CC-BY-SA-4.0** 라이선스로, 모델을 수정한 경우 동일한 라이선스를 적용해야 하는 제약이 있습니다.
  - 사전학습 모델이므로, 실제 사용을 위해서는 승인/반려 분류 데이터로 추가적인 파인튜닝이 반드시 필요합니다.
- **적합성 분석**: 직접 파인튜닝을 진행할 계획이고, 라이선스 조건을 준수할 수 있다면 좋은 기반 모델이 될 수 있습니다. 범용적인 성능을 바탕으로 안정적인 결과를 기대할 수 있습니다.

### 4.4. snunlp/KR-FinBert-SC

- **선택 이유**: 금융 도메인에 특화된 BERT 모델로, 금융 관련 텍스트 분류에서 높은 성능을 보입니다.
- **장점**: 
  - 금융 뉴스, 리포트 등 전문적인 데이터로 학습하여 해당 도메인에 대한 이해도가 높습니다.
- **단점**: 
  - **라이선스가 명시되어 있지 않아** 상업적 이용 가능 여부를 확인해야 합니다.
  - 금융 도메인에 특화되어 있어, 일반적인 알림톡 템플릿 분류에는 도메인 미스매치로 인해 성능이 오히려 저하될 수 있습니다.
- **적합성 분석**: 알림톡 템플릿이 금융 관련 내용을 많이 포함한다면 고려해볼 수 있으나, 일반적인 경우에는 부적합할 가능성이 높습니다. 라이선스 확인이 선행되어야 합니다.

### 4.5. hun3359/klue-bert-base-sentiment

- **선택 이유**: klue/bert-base 모델을 60가지의 세분화된 감정으로 분류하도록 파인튜닝한 모델입니다.
- **장점**: 
  - 단순 긍정/부정을 넘어 미묘한 감정 차이를 분류할 수 있어, 반려 사유를 세분화하는 등 모델을 확장할 때 유용할 수 있습니다.
- **단점**: 
  - **CC-BY-SA-4.0** 라이선스 제약이 있습니다.
  - 60개나 되는 많은 클래스로 학습하여 F1 점수가 0.29로 낮아, 단순 승인/반려 이진 분류 문제에는 오히려 성능이 저하될 수 있습니다.
- **적합성 분석**: 단순 승인/반려 분류에는 과도하게 복잡하고 성능이 낮아 부적합합니다. 추후 모델 고도화 시 반려 사유를 세분화하는 등의 목적이 생길 경우 참고할 수 있습니다.




## 5. 최종 결론 및 추천 사항

### 5.1. 생성 모델 (알림톡 템플릿 생성)

**🥇 1순위 추천: MLP-KTLim/llama-3-Korean-Bllossom-8B**
- **이유**: 상업적 이용이 가능한 Llama 3 라이선스, 한국어에 특화된 instruction tuning, 우수한 벤치마크 성능 등 모든 면에서 균형이 잡혀 있습니다. 알림톡 템플릿 생성이라는 목표에 가장 부합하는 모델입니다.

**🥈 2순위 추천: NCSOFT/Llama-VARCO-8B-Instruct**
- **이유**: LogicKor 벤치마크에서 최고의 성능을 보여준 만큼, 논리적이고 정확한 템플릿 생성에 강점을 보일 것으로 기대됩니다. Bllossom과 함께 테스트하여 더 나은 성능을 보이는 모델을 최종 선택하는 것을 추천합니다.

**💡 기타 의견**: yanolja/EEVE-Korean-Instruct-10.8B-v1.0은 모델 크기가 커서 비용 문제가 발생할 수 있으나, 성능이 뛰어나다면 고려해볼 수 있습니다. LGAI-EXAONE과 Ko-Qwen2 모델은 라이선스 문제로 상업적 이용이 불가능하여 추천하지 않습니다.

### 5.2. 분류 모델 (승인/반려 분류)

**🥇 1순위 추천: Copycats/koelectra-base-v3-generalized-sentiment-analysis**
- **이유**: 상업적 이용이 가능한 Apache 2.0 라이선스, 일반화된 이진 분류 성능, ELECTRA 기반의 효율성 등 요구사항에 가장 잘 부합합니다. 별도의 파인튜닝 없이도 좋은 성능을 기대할 수 있습니다.

**🥈 2순위 추천: daekeun-ml/koelectra-small-v3-nsmc**
- **이유**: MIT 라이선스와 작은 모델 크기로 비용 효율성이 매우 높습니다. NSMC 도메인에 특화된 점이 우려되지만, 파인튜닝을 통해 충분히 극복 가능하며, 빠른 속도가 중요한 서비스에 적합합니다.

**💡 기타 의견**: klue/bert-base는 직접 파인튜닝을 진행할 경우 좋은 선택지가 될 수 있습니다. KR-FinBert와 klue-bert-base-sentiment는 각각 도메인 특수성과 과도한 복잡성으로 인해 이번 프로젝트에는 부적합하다고 판단됩니다.

---

**참고 자료**

- Hugging Face: https://huggingface.co
- KLUE Benchmark: https://klue-benchmark.com/


